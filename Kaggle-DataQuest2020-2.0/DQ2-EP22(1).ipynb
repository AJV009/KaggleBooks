{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQ2-EP22.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOthiwunJJQpJFtf1n/iKKr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yKYdeoUSwhfg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":421},"outputId":"b1279858-caf9-4399-b563-f01c7a3c68d1","executionInfo":{"status":"ok","timestamp":1590058131059,"user_tz":-330,"elapsed":10068,"user":{"displayName":"Alphons Jaimon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqnmvIvk8GxzVOP4jxzzqWQOopwV3fqVzXufB8Nw=s64","userId":"13835250506367315561"}}},"source":["!wget https://raw.githubusercontent.com/AJV009/Machine_Learning_NB/master/datasets/doctor_data/doctor_train.csv\n","!wget https://raw.githubusercontent.com/AJV009/Machine_Learning_NB/master/datasets/doctor_data/doctor_test.csv\n","# !pip install --upgrade mxnet-cu100\n","# !pip install autogluon\n","# !pip install -U ipykernel"],"execution_count":46,"outputs":[{"output_type":"stream","text":["--2020-05-21 10:48:46--  https://raw.githubusercontent.com/AJV009/Machine_Learning_NB/master/datasets/doctor_data/doctor_train.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2571184 (2.5M) [text/plain]\n","Saving to: ‘doctor_train.csv.1’\n","\n","\rdoctor_train.csv.1    0%[                    ]       0  --.-KB/s               \rdoctor_train.csv.1  100%[===================>]   2.45M  --.-KB/s    in 0.1s    \n","\n","2020-05-21 10:48:47 (24.2 MB/s) - ‘doctor_train.csv.1’ saved [2571184/2571184]\n","\n","--2020-05-21 10:48:49--  https://raw.githubusercontent.com/AJV009/Machine_Learning_NB/master/datasets/doctor_data/doctor_test.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 261931 (256K) [text/plain]\n","Saving to: ‘doctor_test.csv.1’\n","\n","doctor_test.csv.1   100%[===================>] 255.79K  --.-KB/s    in 0.03s   \n","\n","2020-05-21 10:48:49 (7.95 MB/s) - ‘doctor_test.csv.1’ saved [261931/261931]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ldkMHGWCwpAq","colab_type":"code","colab":{}},"source":["# import autogluon as ag\n","# from autogluon import TabularPrediction as task\n","import time\n","import pandas as pd, numpy as np, matplotlib.pyplot as plt\n","df = pd.read_csv('doctor_train.csv')\n","tdf = pd.read_csv('doctor_test.csv')\n","\n","cols = ['age','Money','day','Time','Doctor_visits','last_visit',\n","        'cured_in','Profession','Status','edu','Irregular','residence',\n","        'prev_diagnosed','communication','Month','side_effects']\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","le_y = le.fit(df['Y'])\n","df['Y'] = le_y.transform(df['Y'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"86F71lKYrLQ4","colab_type":"code","colab":{}},"source":["# df.info()\n","def dataessing(df):\n","  cat_col = ['Profession','Status','edu','Irregular','residence','prev_diagnosed','communication','Month','side_effects']\n","  num_col = ['age','day','Time','Doctor_visits','last_visit','cured_in']\n","  loan = ['Money']\n","  target = ['Y']\n","  dfc = pd.DataFrame()\n","  dfc[cat_col] = df[cat_col].fillna(\"unknown\")\n","  dfc[num_col+loan] = df[num_col+loan].fillna(0)\n","  dfc[num_col] = dfc[num_col].clip(lower=0)\n","  drop_val = ['last_visit','cured_in']\n","  dfc.drop(drop_val,axis=1,inplace=True)\n","  from sklearn.model_selection import train_test_split\n","  X_train, X_test, y_train, y_test = train_test_split(dfc, df['Y'], random_state=45, test_size=0.3)\n","  return X_train, X_test, y_train, y_test\n","\n","X_train, X_test, y_train, y_test = dataessing(df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sTx3R8c2nV3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":841},"outputId":"af066c18-ef96-49c3-83b7-e901a5a38369","executionInfo":{"status":"error","timestamp":1590058390604,"user_tz":-330,"elapsed":1626,"user":{"displayName":"Alphons Jaimon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqnmvIvk8GxzVOP4jxzzqWQOopwV3fqVzXufB8Nw=s64","userId":"13835250506367315561"}}},"source":["from catboost import CatBoostClassifier\n","model = CatBoostClassifier(\n","    cat_features=X_train.columns.value\n","    # iterations=10, depth=10, learning_rate=0.01, loss_function='Logloss', \n","    verbose=True)\n","model.fit(X_train, y_train)\n","y_hat = model.predict(X_test)\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","print(accuracy_score(y_test, y_hat))\n","print(confusion_matrix(y_test, y_hat))\n","print(classification_report(y_test, y_hat))"],"execution_count":50,"outputs":[{"output_type":"error","ename":"CatBoostError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'blue-collar'' to float","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-c6ea3c5b7e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# iterations=10, depth=10, learning_rate=0.01, loss_function='Logloss',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     verbose=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3995\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   3996\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3998\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m             \u001b[0msave_snapshot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1732\u001b[0m         )\n\u001b[1;32m   1733\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         train_pool = _build_train_pool(X, y, cat_features, text_features, pairs, sample_weight, group_id,\n\u001b[0;32m-> 1619\u001b[0;31m                                        group_weight, subgroup_id, pairs_weight, baseline, column_description)\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0;32m--> 957\u001b[0;31m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[1;32m    958\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, column_description, pairs, delimiter, has_header, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    432\u001b[0m                     )\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n","\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"blue-collar\": Cannot convert 'b'blue-collar'' to float"]}]},{"cell_type":"code","metadata":{"id":"jnN43ySArF3d","colab_type":"code","colab":{}},"source":["def preprocessing(tr,te):\n","  lab = 'Y'\n","  # drop index\n","  tr.drop('ID',1,inplace=True)\n","  te.drop('ID',1,inplace=True)\n","  # impyte missing vales using mean\n","  tr = tr.fillna(0)\n","  te = te.fillna(0)\n","  # get_dummies\n","  tr_DUM = pd.get_dummies(tr.drop(lab,1))\n","  te_DUM = pd.get_dummies(te)\n","  # load new col name\n","  cols = tr_DUM.columns.values\n","  #split for validation\n","  from sklearn.model_selection import train_test_split\n","  X_train, X_test, y_train, y_test = train_test_split(tr_DUM, tr[lab], random_state=0, test_size=0.2)\n","  # SMOTE for training data only!\n","  from imblearn.over_sampling import SMOTE\n","  smt = SMOTE(ratio='auto')\n","  X_sm, y_sm = smt.fit_resample(X_train, y_train)\n","  # convert to dataframe and labels back\n","  X_sm = pd.DataFrame(X_sm)\n","  X_sm.columns = cols\n","  X_sm['Y'] = y_sm # train data prepared\n","  X_test['Y'] = y_test # validation data prepared\n","  return X_sm, X_test, te_DUM\n","\n","train_DF, valid_DF, test_DF = preprocessing(df,tdf)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jNmIjRJpxX9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"d2ed024e-5332-4f22-b82d-84ad55d038de","executionInfo":{"status":"ok","timestamp":1590055035785,"user_tz":-330,"elapsed":7583,"user":{"displayName":"Alphons Jaimon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqnmvIvk8GxzVOP4jxzzqWQOopwV3fqVzXufB8Nw=s64","userId":"13835250506367315561"}}},"source":[""],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4939\n","1     701\n","Name: Y, dtype: int64"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"S26T4EmzyciI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3e727381-2869-466f-aa82-5fe81a4f4341","executionInfo":{"status":"error","timestamp":1590054728468,"user_tz":-330,"elapsed":43022,"user":{"displayName":"Alphons Jaimon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqnmvIvk8GxzVOP4jxzzqWQOopwV3fqVzXufB8Nw=s64","userId":"13835250506367315561"}}},"source":["%%time\n","predictor = task.fit(train_data=train_DF, \n","                     label='Y', \n","                    #  eval_metric='roc_auc',\n","                     eval_metric='accuracy',\n","                     auto_stack=True,\n","                     verbosity=2)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["No output_directory specified. Models will be saved in: AutogluonModels/ag-20200521_095004/\n","Beginning AutoGluon training ...\n","AutoGluon will save models to AutogluonModels/ag-20200521_095004/\n","Train Data Rows:    39896\n","Train Data Columns: 55\n","Preprocessing data ...\n","Here are the first 10 unique label values in your data:  [0 1]\n","AutoGluon infers your prediction problem is: binary  (because only two unique label-values observed).\n","If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: [('binary', 'multiclass', 'regression')])\n","\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Feature Generator processed 39896 data points with 54 features\n","Original Features:\n","\tfloat features: 54\n","\tobject features: 0\n","Generated Features:\n","\tint features: 0\n","All Features:\n","\tfloat features: 54\n","\tobject features: 0\n","\tint features: 0\n","\tData preprocessing and feature engineering runtime = 0.37s ...\n","AutoGluon will gauge predictive performance using evaluation metric: accuracy\n","To change this, specify the eval_metric argument of fit()\n","AutoGluon will early stop models using evaluation metric: accuracy\n","Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n","Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","\n","Unfortunately, your original traceback can not be constructed.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-11-03f7c4101bb8>\", line 1, in <module>\n","    get_ipython().run_cell_magic('time', '', \"predictor = task.fit(train_data=train_DF, \\n                     label='Y', \\n                    #  eval_metric='roc_auc',\\n                     eval_metric='accuracy',\\n                     auto_stack=True,\\n                     verbosity=2)\")\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2117, in run_cell_magic\n","    result = fn(magic_arg_s, cell)\n","  File \"<decorator-gen-60>\", line 2, in time\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\", line 1193, in time\n","    exec(code, glob, local_ns)\n","  File \"<timed exec>\", line 6, in <module>\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/task/tabular_prediction/presets_configs.py\", line 9, in _call\n","    return f(**g(**kwargs))\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/task/tabular_prediction/tabular_prediction.py\", line 531, in fit\n","    hyperparameters=hyperparameters, time_limit=time_limits_orig, save_data=cache_data, save_bagged_folds=save_bagged_folds, verbosity=verbosity)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/learner/default_learner.py\", line 103, in fit\n","    hyperparameters=hyperparameters)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/auto_trainer.py\", line 41, in train\n","    self.train_multi_and_ensemble(X_train, y_train, X_test, y_test, models, hyperparameter_tune=hyperparameter_tune, feature_prune=feature_prune)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 510, in train_multi_and_ensemble\n","    self.train_multi_levels(X_train, y_train, X_test, y_test, models=models, hyperparameter_tune=hyperparameter_tune, feature_prune=feature_prune, level_start=0, level_end=self.stack_ensemble_levels)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 525, in train_multi_levels\n","    self.stack_new_level(X=X_train, y=y_train, X_test=X_test, y_test=y_test, models=models, level=level, hyperparameter_tune=hyperparameter_tune, feature_prune=feature_prune, time_limit_core=time_limit_core, time_limit_aux=time_limit_aux)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 532, in stack_new_level\n","    core_models = self.stack_new_level_core(X=X, y=y, X_test=X_test, y_test=y_test, models=models, level=level, hyperparameter_tune=hyperparameter_tune, feature_prune=feature_prune, time_limit=time_limit_core)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 569, in stack_new_level_core\n","    return self.train_multi(X_train=X_train_init, y_train=y, X_test=X_test, y_test=y_test, models=models, hyperparameter_tune=hyperparameter_tune, feature_prune=feature_prune, level=level, stack_name=stack_name, kfolds=kfolds, n_repeats=n_repeats, time_limit=time_limit)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 484, in train_multi\n","    stack_name=stack_name, level=level, time_limit=time_limit)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 434, in train_multi_initial\n","    kfolds=kfolds, k_fold_start=k_fold_start, k_fold_end=kfolds, n_repeats=n_repeats, n_repeat_start=0, level=level, time_limit=time_limit)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 462, in train_multi_fold\n","    n_repeats=n_repeats, n_repeat_start=n_repeat_start, level=level, time_limit=time_left)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 376, in train_single_full\n","    model_names_trained = self.train_and_save(X_train, y_train, X_test, y_test, model, stack_name=stack_name, kfolds=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, level=level, time_limit=time_limit)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 266, in train_and_save\n","    model = self.train_single(X_train, y_train, X_test, y_test, model, kfolds=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, level=level, time_limit=time_limit)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 249, in train_single\n","    model.fit(X=X_train, y=y_train, k_fold=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=False, time_limit=time_limit, **model_fit_kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in fit\n","    super().fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 193, in fit\n","    fold_model.fit(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, time_limit=time_limit_fold, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/autogluon/utils/tabular/ml/models/rf/rf_model.py\", line 102, in fit\n","    self.model = self.model.fit(X_train, Y_train)\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\", line 383, in fit\n","    for i, t in enumerate(trees))\n","  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1042, in __call__\n","    self.retrieve()\n","  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 921, in retrieve\n","    self._output.extend(job.get(timeout=self.timeout))\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n","    self.wait(timeout)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n","    self._event.wait(timeout)\n","  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n","    signaled = self._cond.wait(timeout)\n","  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n","    waiter.acquire()\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n","    lines, lnum = findsource(frame)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"0Kg2IXweQUX3","colab_type":"code","colab":{}},"source":["y_pred = predictor.predict(valid_DF.drop('Y',1))\n","perf = predictor.evaluate_predictions(valid_DF['Y'], y_pred)\n","results = predictor.fit_summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XKUdm7LDxX4","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","print(accuracy_score(valid_DF['Y'], y_pred))\n","print(confusion_matrix(valid_DF['Y'], y_pred))\n","print(classification_report(valid_DF['Y'], y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qIL-F2wfDZ-S","colab_type":"code","colab":{}},"source":["y_hat = predictor.predict(test_DF)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"svICn_VKRUER","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":246},"outputId":"b6041aa9-177d-400b-8e72-1e05d093fdab","executionInfo":{"status":"error","timestamp":1590050152122,"user_tz":-330,"elapsed":1169,"user":{"displayName":"Alphons Jaimon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqnmvIvk8GxzVOP4jxzzqWQOopwV3fqVzXufB8Nw=s64","userId":"13835250506367315561"}}},"source":["Y = le_y.inverse_transform(y_hat)\n","output = pd.DataFrame({'id': tdf.ID,\n","                       'Y': Y})\n","output.to_csv('submissionSMOTETomek.csv', index=False)\n","from google.colab import files\n","files.download('submissionSMOTETomek.csv')"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-67246f25e7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m output = pd.DataFrame({'id': tdf.ID,\n\u001b[1;32m      3\u001b[0m                        'Y': Y})\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submissionSMOTETomek.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'le_y' is not defined"]}]},{"cell_type":"code","metadata":{"id":"-oepjBxeXvjZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}