{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.RNN-play-generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEqhz8e3nebc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGn7NiUn1Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "df1e3e71-d4ef-45cd-df21-fad778563e5e"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9AUgT4soq5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z9uuoyBpag_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(path_to_file,'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en9_Po_QptVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_int(text): return np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp2OpVtNpvCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8a6581d8-f0c2-4c86-f5cd-4d4c775295fd"
      },
      "source": [
        "print(\"TEXT: \",text[:20])\n",
        "print(\"ENCODED: \",text_int(text[:20]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEXT:  First Citizen:\n",
            "Befor\n",
            "ENCODED:  [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Yud15rsCxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "355f4db6-f591-4bb1-e097-e70cb21131a8"
      },
      "source": [
        "# def int_text(ints):\n",
        "#   try:\n",
        "#     ints = ints.numpy()\n",
        "#   except:\n",
        "#     pass\n",
        "  # return ''.join(idx2char[ints])\n",
        "def int_text(ints): return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_text(text_int(text[:20])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Befor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3XrZSFHsrbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length =100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_int(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOU2OtcCPmIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MB5HhyzP1VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heev48ruQI1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "buffer_size = 10000\n",
        "data = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFvKLyFyTQYR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c6e383c1-c717-4b65-ea12-d8cbac525815"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "                               tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                               tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhfWQiJaUF-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d6ffb55-e1e4-48b4-ff1c-d5b8c680a9fb"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk68y3wSWorD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31ce0ec5-072e-4f12-fe4c-4007a7e0887d"
      },
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)\n",
        "\n",
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)\n",
        "\n",
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_text(sampled_indices)\n",
        "\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 1.62878609e-03  4.86297067e-03  2.51444941e-03 ... -1.35758182e-03\n",
            "    2.37798179e-03 -6.24486897e-03]\n",
            "  [-2.10060272e-03  9.32632945e-03  3.01539549e-03 ... -8.80539417e-03\n",
            "    1.48707535e-04 -3.34495050e-03]\n",
            "  [ 6.75477227e-03  2.69828341e-03  1.52128970e-03 ... -2.02095928e-03\n",
            "   -8.23725015e-04 -6.27625547e-03]\n",
            "  ...\n",
            "  [ 8.99430364e-04  4.71661333e-03  5.10351965e-03 ... -5.21392468e-03\n",
            "   -3.24455672e-04 -6.20030006e-03]\n",
            "  [ 9.09179635e-03 -4.49290965e-04  3.32246581e-03 ...  1.18604198e-03\n",
            "   -1.52763212e-03 -8.69839359e-03]\n",
            "  [ 5.84403891e-03 -1.21804141e-03  3.25670023e-03 ... -1.41509401e-03\n",
            "    2.48032017e-03 -8.27911124e-03]]\n",
            "\n",
            " [[ 5.08736540e-03 -2.72444473e-03  3.57016525e-03 ...  1.93215499e-03\n",
            "   -2.69525335e-03  6.00479171e-03]\n",
            "  [ 2.82403245e-03 -5.35125146e-03  1.89822773e-03 ... -2.87961657e-03\n",
            "    2.01648776e-03  1.06530508e-03]\n",
            "  [ 3.40052322e-03 -7.33436598e-03 -7.07694096e-04 ... -5.22416364e-03\n",
            "    1.09854178e-03  3.32423090e-03]\n",
            "  ...\n",
            "  [ 4.27809544e-03 -3.39270802e-03  1.01778004e-03 ...  3.25829675e-03\n",
            "   -9.69886407e-03 -8.85697547e-03]\n",
            "  [ 8.34702142e-03  4.69809584e-03  7.48277735e-03 ...  5.05363476e-03\n",
            "   -1.01511236e-02 -4.92791459e-03]\n",
            "  [ 1.15216756e-02  1.82672241e-03  5.58948703e-03 ...  1.96114043e-03\n",
            "   -1.05428332e-02 -1.68144330e-03]]\n",
            "\n",
            " [[-1.87878113e-03 -3.31711886e-03  7.07430765e-04 ... -4.08793520e-03\n",
            "    3.55857215e-03 -3.81013006e-03]\n",
            "  [ 1.81455794e-03 -5.36335632e-03 -4.34531644e-03 ... -2.49422994e-03\n",
            "    1.21277384e-03 -4.55243420e-03]\n",
            "  [ 4.81621735e-03 -7.09041534e-03 -8.14821851e-03 ... -1.26857171e-03\n",
            "   -2.17342284e-04 -5.26025612e-03]\n",
            "  ...\n",
            "  [ 1.70673504e-02 -6.77393749e-03  3.11647053e-03 ... -3.90674453e-04\n",
            "   -5.50840888e-03 -2.60059256e-04]\n",
            "  [ 1.34831211e-02 -3.05914134e-03  9.79494024e-03 ... -6.19708002e-03\n",
            "   -1.05198184e-02 -5.17499819e-03]\n",
            "  [ 1.88670419e-02 -6.33408409e-03  6.19985163e-03 ... -2.44768336e-03\n",
            "   -1.05037643e-02 -4.65007545e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 7.45120784e-03 -4.56259120e-03 -1.31821027e-03 ...  4.07119934e-03\n",
            "   -1.38308108e-03 -2.43897969e-03]\n",
            "  [ 6.46588299e-03 -9.70551372e-03  6.56063482e-03 ...  2.28805467e-03\n",
            "   -7.51602056e-04 -8.67578667e-04]\n",
            "  [ 3.00749158e-03 -3.32478178e-03  5.02844388e-03 ...  6.56674709e-03\n",
            "   -3.37917963e-03 -1.45001756e-03]\n",
            "  ...\n",
            "  [ 1.11714676e-02 -8.54258332e-03 -4.42115683e-03 ...  7.05344509e-03\n",
            "   -9.08765104e-03 -1.01052306e-03]\n",
            "  [ 9.39517934e-03 -1.11473445e-02 -1.13560236e-03 ...  6.62928633e-03\n",
            "   -6.10813219e-03  4.22437396e-03]\n",
            "  [ 5.30913007e-03 -9.61066131e-03  3.84372426e-04 ...  4.78975428e-03\n",
            "   -4.00116481e-03  5.05512580e-03]]\n",
            "\n",
            " [[ 7.45120784e-03 -4.56259120e-03 -1.31821027e-03 ...  4.07119934e-03\n",
            "   -1.38308108e-03 -2.43897969e-03]\n",
            "  [ 4.34082933e-03 -2.49872636e-03  1.02674623e-03 ...  5.97224524e-03\n",
            "    6.11341558e-04 -4.26773028e-03]\n",
            "  [ 1.26114790e-03 -3.57225654e-03  1.23046932e-03 ...  1.46589428e-03\n",
            "    3.01685883e-03 -7.46441446e-03]\n",
            "  ...\n",
            "  [ 6.11470174e-03  2.10683793e-05  9.23579186e-03 ...  4.19105985e-04\n",
            "   -1.11426637e-02 -1.08958241e-02]\n",
            "  [ 3.52114625e-03 -1.18222553e-03  7.74007104e-03 ... -3.49254021e-03\n",
            "   -5.97093301e-03 -7.05737947e-03]\n",
            "  [ 5.20469109e-03  3.85077298e-03  9.53859370e-03 ... -4.15976439e-03\n",
            "   -2.79906322e-03 -1.02138333e-02]]\n",
            "\n",
            " [[-1.87878113e-03 -3.31711886e-03  7.07430765e-04 ... -4.08793520e-03\n",
            "    3.55857215e-03 -3.81013006e-03]\n",
            "  [-5.00757305e-04  3.09618725e-03 -5.70738921e-05 ... -3.81710450e-03\n",
            "    8.48241616e-05 -3.17138294e-03]\n",
            "  [ 8.66587739e-03 -2.23412365e-03 -1.34162977e-03 ...  1.50418829e-03\n",
            "   -2.57892441e-03 -4.56855213e-03]\n",
            "  ...\n",
            "  [-3.06679145e-03  4.68023587e-04  4.16298490e-03 ...  1.01393200e-02\n",
            "   -4.27793618e-03  2.03990098e-03]\n",
            "  [-2.01549288e-03 -6.09095907e-03  1.11535490e-02 ...  5.31802420e-03\n",
            "   -2.76407134e-03  2.60215439e-03]\n",
            "  [-8.34590755e-03 -5.54609951e-03  6.89246505e-03 ...  4.38831281e-03\n",
            "   -9.29460116e-03  5.05936705e-03]]], shape=(64, 100, 65), dtype=float32)\n",
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00162879  0.00486297  0.00251445 ... -0.00135758  0.00237798\n",
            "  -0.00624487]\n",
            " [-0.0021006   0.00932633  0.0030154  ... -0.00880539  0.00014871\n",
            "  -0.00334495]\n",
            " [ 0.00675477  0.00269828  0.00152129 ... -0.00202096 -0.00082373\n",
            "  -0.00627626]\n",
            " ...\n",
            " [ 0.00089943  0.00471661  0.00510352 ... -0.00521392 -0.00032446\n",
            "  -0.0062003 ]\n",
            " [ 0.0090918  -0.00044929  0.00332247 ...  0.00118604 -0.00152763\n",
            "  -0.00869839]\n",
            " [ 0.00584404 -0.00121804  0.0032567  ... -0.00141509  0.00248032\n",
            "  -0.00827911]], shape=(100, 65), dtype=float32)\n",
            "65\n",
            "tf.Tensor(\n",
            "[ 1.6287861e-03  4.8629707e-03  2.5144494e-03  9.6229848e-04\n",
            " -2.1768063e-03 -3.7343642e-03 -2.9044207e-03  4.6899645e-03\n",
            " -2.7804619e-03 -3.1641820e-03  8.7413122e-05  2.1726942e-04\n",
            "  5.1564528e-03 -2.3758595e-03  4.4563208e-03  2.8871696e-03\n",
            " -7.9753791e-04 -2.2063875e-03  1.9519607e-03 -1.2312125e-04\n",
            " -5.6687160e-05 -1.6381503e-03 -3.8224836e-03  3.7691267e-03\n",
            " -1.0395634e-03  1.7982513e-03 -1.4366591e-03  3.4272794e-03\n",
            "  5.2480260e-04 -1.4769580e-03 -3.0205389e-03  2.0104521e-03\n",
            "  5.4286243e-03 -7.6566203e-03 -3.5542483e-03 -4.7293175e-03\n",
            " -1.4584884e-03  1.2535813e-03 -6.2973299e-03 -1.5642153e-03\n",
            " -2.0675464e-03 -2.5297000e-04 -2.7989093e-03 -1.2225691e-03\n",
            " -7.8984778e-03 -5.6731456e-04  4.1721249e-03 -1.6625938e-03\n",
            " -1.5458365e-03  1.3717150e-03  6.5594893e-03 -6.9417544e-03\n",
            "  1.5526675e-03  8.6701947e-04 -1.8436804e-03 -1.1201894e-03\n",
            "  2.2178795e-03  5.2328338e-03 -2.9645632e-03 -9.1170305e-03\n",
            "  4.1520344e-03  8.8403758e-04 -1.3575818e-03  2.3779818e-03\n",
            " -6.2448690e-03], shape=(65,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQlWs4YXGPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk4_eJpcXDG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b9340be-4236-4d1a-ca6e-d81cd0e48d26"
      },
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 2.5955\n",
            "Epoch 2/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.8945\n",
            "Epoch 3/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.6424\n",
            "Epoch 4/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.5060\n",
            "Epoch 5/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.4246\n",
            "Epoch 6/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3687\n",
            "Epoch 7/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3232\n",
            "Epoch 8/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.2839\n",
            "Epoch 9/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.2474\n",
            "Epoch 10/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.2135\n",
            "Epoch 11/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.1792\n",
            "Epoch 12/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.1423\n",
            "Epoch 13/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.1054\n",
            "Epoch 14/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.0675\n",
            "Epoch 15/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.0271\n",
            "Epoch 16/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.9871\n",
            "Epoch 17/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.9446\n",
            "Epoch 18/50\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.9048\n",
            "Epoch 19/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.8649\n",
            "Epoch 20/50\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.8255\n",
            "Epoch 21/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.7887\n",
            "Epoch 22/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.7533\n",
            "Epoch 23/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.7215\n",
            "Epoch 24/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.6937\n",
            "Epoch 25/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.6649\n",
            "Epoch 26/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.6408\n",
            "Epoch 27/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.6194\n",
            "Epoch 28/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5990\n",
            "Epoch 29/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5813\n",
            "Epoch 30/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5628\n",
            "Epoch 31/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5490\n",
            "Epoch 32/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5356\n",
            "Epoch 33/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5227\n",
            "Epoch 34/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5124\n",
            "Epoch 35/50\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.5015\n",
            "Epoch 36/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4913\n",
            "Epoch 37/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4828\n",
            "Epoch 38/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4765\n",
            "Epoch 39/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4704\n",
            "Epoch 40/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4648\n",
            "Epoch 41/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4585\n",
            "Epoch 42/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4537\n",
            "Epoch 43/50\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.4491\n",
            "Epoch 44/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4450\n",
            "Epoch 45/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4404\n",
            "Epoch 46/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4368\n",
            "Epoch 47/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4355\n",
            "Epoch 48/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4328\n",
            "Epoch 49/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4284\n",
            "Epoch 50/50\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.4243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f9f70fce17e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'VOCAB_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQPU8xorXiR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUK1GFkkXIPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJT_FdrRXNDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "41b2e9be-05b7-4890-820b-f7f348ed0d8c"
      },
      "source": [
        "checkpoint_num = 10\n",
        "model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-97614ead033d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_checkpoints/ckpt_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m           'True when by_name is True.')\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m       \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_is_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[1;32m   1617\u001b[0m           filepath.endswith('.hdf5'))\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python._pywrap_checkpoint_reader.Checkp' object has no attribute 'endswith'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ5BS0ZFXO9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 800\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    \n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz5vIwMNXRwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "c123d33f-ed6c-4191-b7dc-47954063f3c8"
      },
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type a starting string: romeo\n",
            "romeour\n",
            "Art tall'd with virtuous that ride so state\n",
            "And bitter than theyer.\n",
            "\n",
            "ROMEO:\n",
            "If I may trust, if God f pity give us becomes my mistress' head;\n",
            "The knightful block news, wanting, after thoughts,\n",
            "I'll mend it much dis sendency to oppenith,\n",
            "In peeping hot the letter with the goast\n",
            "Which eyes the wolf.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "By heavens, I pray thee, gove a corple, but that\n",
            "scarce for your nept way to-nir--\n",
            "\n",
            "First Citizen:\n",
            "I the great cousin, ever.\n",
            "\n",
            "VOLUMNIA:\n",
            "O, good my lord, despite; I must forget it,\n",
            "Rather than honour of himself, hid\n",
            "From these old Gloucester's pardon.\n",
            "\n",
            "MENENIUS:\n",
            "Sir, that's oppress:\n",
            "Therefore accompand us with well-spoken, and none suspected.\n",
            "\n",
            "BIONDELLO:\n",
            "Why, is it not now and now you are\n",
            "To shrie king and stends already; and in the\n",
            "sequever than at home by the evil diet and\n",
            "dus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isPdrhuRXvvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}